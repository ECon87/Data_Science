#+TITLE: Various ML and NLP Notes

* Natural Language Processing
 
** Frameworks
   - NLTK and Spacy
   - Hugging face (Bert, transformers, pipelines) <-> PyTorch and Tensorflow implementations
     - [[https://www.youtube.com/watch?v=GSt00_-0ncQ&t=291s][YT Video on basics]]
     - [[https://huggingface.co/transformers/v1.2.0/index.html][PyTorch Hugging Face]]
     - [[https://datascience.stackexchange.com/questions/73761/implementation-of-bert-using-tensorflow-vs-pytorch][stack exchange explanation]]
   - RoBERTa  [[https://www.youtube.com/watch?v=DQc2Mi7BcuI][YT video]] and [[https://arxiv.org/abs/1907.11692][arxiv paper]]
   - TextBlob
   - Vader
     - [[https://www.youtube.com/watch?v=qTyj2R-wcks][YT video for Vader and TextBlob]]
  
** Imbalanced Samples
   - Augmentation and Over-sampling
     [[https://www.youtube.com/watch?v=ubxfWPg2dJ0][Interesting YT video]]

     Augmentation: create new observations from current observations.

** Example: VADER Sentiment Analyzer
 #+BEGIN_SRC elisp
 (setq org-babel-python-command "/home/econ87/venvs/MLNLP/bin/python")
 #+END_SRC

 #+RESULTS:
 : /home/econ87/venvs/MLNLP/bin/python

 #+TITLE:Sentiment Analysis using VADER


*** Introduction
    Sentiment analysis detects polarity (e.g., positive, negative and neutral) within a piece of text.
    Sentiment analysis aims to measure the attitude, sentiments, evaluations, attitudes, and emotions of a speaker/writer based on the computation treatment of subjectivity in a text.

*** Why is Sentiment Analysis difficult to perform?
    A text might contain multiple sentiments:
    #+BEGIN_QUOTE
    The acting was good, but the movie could have been better.
    #+END_QUOTE

*** VADER
    VADER (Valence Aware Dictionary for Sentiment Reasoning) is a model used for text analysis that is sensitive to both polarity (positive/negative) and intensity (strength) of emotion.
    It is available in the NLTK package and can be applied *directly to unlabeled text data*.

    VADER sentimental analysis relies on a dictionary that maps lexical features to emotion intensities known as sentiment scores.
    The sentiment score of a text can be obtained by summing up the intensity of each word in the text.

    For example, words like /love/, /enjoy/, /happy/, /like/ all convey a positive sentiment.
    Also, VADER is intelligent enough to understand the basic context of these words, such as /did not love/ as a negative sentiment.
    It also understands the emphasis of capitalization and punctuation, such as /ENJOY/.
  
*** Polarity classification
    We will not try to determine if a sentence is objective or subjective, fact or opinion.
    Rather, we care if the text expresses a /positive/, /negative/, or /neutral/ opinion.
  
*** Document-level scope
    We will also try to aggregate all of the sentences in a document or paragraph to arrive at an overall opinion.

*** Coarse analysis
    We will not try to perform a fine-grained analysis that would determine the degree of positive/negativity.
    That is, we are not trying to guess how many stars a reviewer awarded, just whether it was positive or negative.
  
*** Broad Steps:
    - First, consider the text being analyzed. A model trained on paragraph-long reviews might not be effective.
    - 
    - Broad Steps:
      - First, consider the text being analyzed.
        A model trained on paragraph-long reviews might not be effective.
        Make sure to use an appropriate model for the task at hand.
      - Next, decide the type of analysis to perform.
        Some rudimentary sentiment analysis models go one step further, and consider two-word combinations, or /bigrams/.
        We will be going to work on complete sentences, and for this we're going to import a trained NLTK lexicon called *VADER*.

*** Datasets to use
    We can use a variety of datasets like amazon reviews, movie reviews, or any other reviews for any product.


  #+BEGIN_SRC python :session prep :results output
     import ntlk
     nltk.download('vader_lexicon')
     from nltk.sentiment.vader import SentimentIntensityAnalyzer

     sid = SentimentIntensityAnalyzer()
  #+END_SRC

  VADER's ~SentimentIntensityAnalyzer()~ takes a string and returns a dictionary of scores in each of four categories:
  - negative
  - neutral
  - positive
  - compound (computed by normalizing the scores above).
  -
  #+BEGIN_SRC python :session prep :results output
        a = 'This was a good movie.'
      print(sid.polarity_scores(a))

    a = 'This was the best, most awesome movie EVER MADE!!!'
  print(sid.polarity_scores(a))
  #+END_SRC

*** Use VADER to analyze Reviews
  
  #+BEGIN_SRC python :session prep :results output
    import numpy as np
    import pandas as pd

    df = pd.read_csv('./path/reviews.tsv', sep = '\t')
    df.head()
    df['label'].value_counts()
  #+END_SRC

*** Clean the data (optional)
    Clean any blank spaces with the reviews.

  #+BEGIN_SRC python :session prep :results output
    df.dropna(inplace = True)

    blanks = [] # start with an empty list

    for i, lb, rv in df.itertuples():
       if type(rv) == str:
          if rv.isspace():
             blanks.append(i)

  df.drop(blanks, inplace = True)
  #+END_SRC

*** Adding Scores and Labels to the DataFrame
    We will add columns to the original DataFrame to store polarity_score dictionaries, extracted compound scores, and new "pos/neg" labels derived from the compound score.
    We will use this last column to perform an accuracy test.
    The reviews in this method will be classified into negative, positive, and neutral ration.

  #+BEGIN_SRC python :session prep :results output
  df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))

  df.head()
  #+END_SRC

  Now call the compound as a separate column and all values greater than zeroes will be considered will be considered a positive review and all values less than zero would be considered as a negative review.

  #+BEGIN_SRC python :session prep :results output
  df['compound'] = df['review'].apply(lambda score_dict: score_dict['compound'])
  df['comp_score'] = df['compound'].apply(lambda c: 'pos' if c >= 0 else 'neg')

  df.head()
  #+END_SRC


  We now have a complete analysis of every review as either positive or negative.

  Let's check some new reviews.

  #+BEGIN_SRC python :session prep :results output
      review = 'The shoes I bought were amazing.'
      print(sid.polarity_scores(review))

      review = 'The mobile phone I bough was the WORST and very BAD.'
      print(sid.polarity_scores(review))
  #+END_SRC

   
** Some links
  
 - [[https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664][towardsdatascience link]]
 - [[https://python-bloggers.com/2020/10/how-to-run-sentiment-analysis-in-python-using-vader/][python bloggers]]
 - [[https://github.com/tstewart161/Reddit_Sentiment_Trader/blob/main/main.py][reddit sentiment]]
 - [[https://medium.com/ro-data-team-blog/nlp-how-does-nltk-vader-calculate-sentiment-6c32d0f5046b][medium]]
 - [[https://www.nltk.org/howto/sentiment.html][nltk howto]]
 - [[https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/][geeks for geeks]]
* Machine Learning
** Imbalanced Samples
   - [[https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/][8 Tactics for dealing with imbalanced samples]]
   - [[https://stackoverflow.com/questions/15065833/imbalance-in-scikit-learn][stackoverflow and imbalanced-learn library cousing of sklearn]]
     - [[https://imbalanced-learn.org/stable/][imbalance website]]
** Cross Validation

[[https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/][link 1]], [[https://scikit-learn.org/stable/modules/cross_validation.html][link2]]
